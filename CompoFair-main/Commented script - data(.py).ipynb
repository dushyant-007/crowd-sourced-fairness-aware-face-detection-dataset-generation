{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from black import diff\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import islice\n",
    "\n",
    "# def take(n, iterable):\n",
    "#     \"Return first n items of the iterable as a list\"\n",
    "#     return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a csv file with path name, image ID and identity\n",
    "# Corrected lines of code to include appropriate directory, and split with extra condition to get ID\n",
    "# Assertion error where identity is null - occurs because some images have 0013_left_eye etc.\n",
    "\n",
    "def gen_celeba_csv(images='./dataset/celeba/images/1', identity='./dataset/celeba/identity_CelebA.txt'):\n",
    "\timgs = [x for x in glob.glob(os.path.join(images, '*'))]\n",
    "# \tprint(imgs)\n",
    "\tcsv = pd.DataFrame(imgs, columns=['path'])\n",
    "\tcsv['id'] = csv['path'].str.split('/').str[-1]\n",
    "\tcsv['id'] = csv['id'].str.split(\"\\\\\").str[-1]\n",
    "# \tdisplay(csv)\n",
    "\tidentity = {line.split()[0]:line.split()[1].strip() for line in open(identity).readlines()}\n",
    "\tattributes = [line.strip().split() for line in open('./dataset/celeba/list_attr_celeba.txt').readlines()[2:]]\n",
    "\tattri_cols = open('./dataset/celeba/list_attr_celeba.txt').readlines()[1].strip().split(' ')\n",
    "# \tprint(take(3, identity.items()))\n",
    "\tcsv['identity'] = csv['id'].map(identity)\n",
    "# \tdisplay(csv[csv['identity'].isnull()])\n",
    "# \tassert not csv['identity'].isnull().any()\n",
    "\tattributes = pd.DataFrame(attributes, columns=['id']+attri_cols)\n",
    "\tcsv = csv.merge(attributes, on='id')\n",
    "\tcsv[csv=='-1'] = 0\n",
    "# \tdisplay(csv)\n",
    "\tcsv.to_csv('./dataset/celeba/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_celeba_csv(images='./dataset/celeba/images', identity='./dataset/celeba/identity_CelebA.txt'):\n",
    "\timgs = [x for x in glob.glob(os.path.join(images, '*'))]\n",
    "\tcsv = pd.DataFrame(imgs, columns=['path'])\n",
    "\tcsv['id'] = csv['path'].str.split('/').str[-1]\n",
    "\tidentity = {line.split()[0]:line.split()[1].strip() for line in open(identity).readlines()}\n",
    "\tattributes = [line.strip().split() for line in open('./dataset/celeba/list_attr_celeba.txt').readlines()[2:]]\n",
    "\tattri_cols = open('./dataset/celeba/list_attr_celeba.txt').readlines()[1].strip().split(' ')\n",
    "\tcsv['identity'] = csv['id'].map(identity)\n",
    "# \tassert not csv['identity'].isnull().any()\n",
    "\tattributes = pd.DataFrame(attributes, columns=['id']+attri_cols)\n",
    "\tcsv = csv.merge(attributes, on='id')\n",
    "\tcsv[csv=='-1'] = 0\n",
    "\tdisplay(csv)\n",
    "\tcsv.to_csv('./dataset/celeba/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm used for monitoring progress\n",
    "# csv file from gen_celeba_csv used for loading the file and encode it into a 128 dim vector\n",
    "\n",
    "def gen_celeba_embeds(csv='./dataset/celeba/data.csv'):\n",
    "\timport face_recognition\n",
    "\tcsv = pd.read_csv(csv)\n",
    "\tfor path in tqdm(csv['path']):\n",
    "\t\timg = face_recognition.load_image_file(path)\n",
    "\t\ttry:\n",
    "\t\t\tembed = face_recognition.face_encodings(img)[0]\n",
    "# \t\t\tprint(embed)            \n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\t\tsave = path.replace('images', 'embeds')+'.npy'\n",
    "\t\tfolder = '/'.join(save.split('/')[:-1])\n",
    "\t\tif not os.path.exists(folder):\n",
    "\t\t\tos.makedirs(folder)\n",
    "\n",
    "\t\tnp.save(save, embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202599"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_names():\n",
    "\t# creates a dictionary for each image (key) and the person appears on it (value)\n",
    "\tnames_path = './dataset/celeba/identity_CelebA.txt'\n",
    "\tnames = {}\n",
    "\twith open(os.path.join(os.getcwd(), names_path), 'r') as f:\n",
    "\t\tdata = f.readlines()\n",
    "\t\tfor i in data:\n",
    "\t\t\tpair = i.split()\n",
    "\t\t\tnames.update({pair[0] : pair[1]})\n",
    "\treturn names\n",
    "\n",
    "# create a global variable that contains all people's names\n",
    "all_names = build_names()\n",
    "len(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates list of 'B' images' paths\n",
    "\n",
    "def gen_img_batch(B = 3, names = all_names):\n",
    "\timport random\n",
    "\n",
    "\t# all image feat Nxd and the path for each image\n",
    "\timages ='./dataset/celeba/images'\n",
    "\tpaths = [x for x in glob.glob(os.path.join(images, '*', '*')) if len(x.split('/')[-1].split('\\\\')[-1]) == 10]\n",
    "\n",
    "\twhile True:\n",
    "\t\t# randomly select B images from paths\n",
    "\t\tl = random.sample(paths, B)\n",
    "\n",
    "\t\tduplicate_names = {}\n",
    "\t\tfor i in l:\n",
    "\t\t\timg = i.split('/')[-1].split('\\\\')[-1]\n",
    "\t\t\teach_name = names.get(img)\n",
    "\t\t\tif each_name in duplicate_names:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tduplicate_names.update({each_name : 1})\n",
    "\t\tbreak\n",
    "\treturn l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil copy(src, dest) - syntax\n",
    "# first condition only works if /pool has no contents - but had to create folders 1, 2 & 3\n",
    "# second condition samples 30 images from pool into _pool\n",
    "\n",
    "def gen_batches(num=1000):\n",
    "\tif len(os.listdir('./dataset/celeba/pool')) == 0:\n",
    "\t\tprint('#')        \n",
    "\t\tres = []\n",
    "\t\tfor _ in range(num):\n",
    "\t\t\t_res = []\n",
    "\t\t\timgs = gen_img_batch(B=3)\n",
    "\t\t\tfor x in imgs:\n",
    "\t\t\t\t_x = '/'.join(x.split('/')[:-2] + x.split('/')[-1:])\n",
    "\t\t\t\tshutil.copy(x, _x.replace('images', 'pool'))\n",
    "\t\t\t\t_res.append(_x.replace('images', 'pool'))\n",
    "\t\t\tres.append(_res)\n",
    "\t\tres = pd.DataFrame(res, columns=['img1', 'img2', 'img3'])\n",
    "\t\tres.to_csv('./dataset/celeba/pool.csv', index=False)\n",
    "\telse:\n",
    "\t\tcsv = pd.read_csv('./dataset/celeba/pool.csv')\n",
    "\t\tcsv.sample(30).to_csv('./dataset/celeba/_pool.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned batch data seems to be crowdsourced with the question - which two faces are similar?\n",
    "# valid adjs if adj occurs more than 'v' times in the fucntion get_valid_adjs (v=10)\n",
    "# prints commonly occuring adjs related to facial components\n",
    "# a1, a2 are the two similar images with same component compo, adjective adj1 while the same component of the third image has adj2\n",
    "\n",
    "def gen_face_data_csv():\n",
    "\tdef get_valid_adjs(csv):\n",
    "\t\tmaps = csv['adj1'].value_counts().to_dict()\n",
    "\t\tmaps.update(csv['adj2'].value_counts().to_dict())\n",
    "\t\tadjs = [k for k, v in maps.items() if v > 10]\n",
    "\n",
    "\t\treturn adjs\n",
    "\n",
    "\tidx2compo = {i+1:x for i, x in enumerate(['forehead', 'eyebrow', 'eye', 'mouth', 'chin', 'cheek', 'nose', 'ear', 'temple', 'nostril', 'tooth', 'lip', 'tongue', 'skin'])}\n",
    "\n",
    "\tcsv = pd.read_csv('./BatchData/cleaned_batch.csv')\n",
    "\tcsv = csv[csv['Reject'].isnull()]\n",
    "\t#Removing images that have been rejected     \n",
    "\tcsv = csv[['Input.img1', 'Input.img2', 'Input.img3', 'Answer.a1', 'Answer.a2', 'Answer.compo', 'Answer.d1', 'Answer.d2']].rename(\n",
    "\t\tcolumns={'Input.img1': 'img1', 'Input.img2': 'img2', 'Input.img3': 'img3',\n",
    "\t\t'Answer.a1': 'a1', 'Answer.a2': 'a2', 'Answer.compo': 'compo', 'Answer.d1': 'adj1', 'Answer.d2': 'adj2'}\n",
    "\t)\n",
    "\tcsv['compo'] = csv['compo'].map(idx2compo)\n",
    "\tfor adj in ['adj1', 'adj2']:\n",
    "\t\tcsv[adj] = csv[adj].str.lower()\n",
    "\t\tcsv[adj] = csv[adj].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\t\tcsv[adj] = csv[adj].str.replace('white', 'light')\n",
    "\t\tcsv[adj] = csv[adj].str.replace('lighter', 'light')\n",
    "\t\tcsv[adj] = csv[adj].str.replace('darker', 'dark')\n",
    "\t\tcsv[adj] = csv[adj].str.replace('black', 'dark')\n",
    "\n",
    "\t# with open('./dataset/celeba/valid_adjs.txt', 'w') as f:\n",
    "\t# \tfor x in set(csv['adj1'].tolist()+csv['adj2'].tolist()):\n",
    "\t# \t\tf.write('{}\\n'.format(x))\n",
    "\n",
    "\tvalid_adjs = get_valid_adjs(csv)\n",
    "\tcsv = csv[csv['adj1'].isin(valid_adjs)]\n",
    "\tcsv = csv[csv['adj2'].isin(valid_adjs)]\n",
    "\tcsv['a1'] -= 1\n",
    "\tcsv['a2'] -= 1\n",
    "\tcsv = csv[csv['a1']!=csv['a2']]\n",
    "\n",
    "\tcsv = csv.groupby('compo').filter(lambda x: len(x)>10)\n",
    "\tfor name, group in csv.groupby('compo'):\n",
    "\t\tprint('------{}'.format(name))\n",
    "\t\tadjs = set(tuple(zip(group['adj1'], group['adj2'])))\n",
    "\t\tprint('{} {} {} adjs for description'.format(name, len(group), len(adjs)))\n",
    "\t\tprint(adjs)\n",
    "\tcsv.to_csv('./dataset/celeba/crowd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>identity</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [path, id, identity, 5_o_Clock_Shadow, Arched_Eyebrows, Attractive, Bags_Under_Eyes, Bald, Bangs, Big_Lips, Big_Nose, Black_Hair, Blond_Hair, Blurry, Brown_Hair, Bushy_Eyebrows, Chubby, Double_Chin, Eyeglasses, Goatee, Gray_Hair, Heavy_Makeup, High_Cheekbones, Male, Mouth_Slightly_Open, Mustache, Narrow_Eyes, No_Beard, Oval_Face, Pale_Skin, Pointy_Nose, Receding_Hairline, Rosy_Cheeks, Sideburns, Smiling, Straight_Hair, Wavy_Hair, Wearing_Earrings, Wearing_Hat, Wearing_Lipstick, Wearing_Necklace, Wearing_Necktie, Young]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tgen_celeba_csv()\n",
    "# \tgen_celeba_embeds()\n",
    "# \tbuild_names()\n",
    "# \tl = gen_img_batch()\n",
    "# \tgen_batches()\n",
    "# \tgen_face_data_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
